{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e636f617-3fad-48c0-926b-79eec11441fe",
      "metadata": {
        "id": "e636f617-3fad-48c0-926b-79eec11441fe"
      },
      "source": [
        "Testing the implementaion of All positive values using 8 Qubits - 256 data points. The weights are obtained from pre training using a simulator and tested in the Cat Qubits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be78276-ba16-4997-acc8-327e8936f0e3",
      "metadata": {
        "id": "9be78276-ba16-4997-acc8-327e8936f0e3"
      },
      "source": [
        "The experimental code for developing Amplitude embedded circuits using Variational Quantum State Preparation (VQSP). The VQSP algorithm uses PQC to create training circuits which learns the parameters to create the corresponding amplitude embedded states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ae60a68f-eb91-48fa-acdd-f182c9973c22",
      "metadata": {
        "id": "ae60a68f-eb91-48fa-acdd-f182c9973c22"
      },
      "outputs": [],
      "source": [
        "# !pip install pennylane nftopt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/QuantumETS/pennylane-alice-bob.git@main"
      ],
      "metadata": {
        "id": "bSI4rTQ-r7PS"
      },
      "id": "bSI4rTQ-r7PS",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f619c0e1-7048-46bf-9220-4060ed674c17",
      "metadata": {
        "id": "f619c0e1-7048-46bf-9220-4060ed674c17"
      },
      "source": [
        "We specify the number of qubits needed to map the data, for n qubits we can amplitude embedded 2^n data. The depth represents the ansatz repitition depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "36a2c84f-0092-4fd2-a84c-daeff317dd48",
      "metadata": {
        "id": "36a2c84f-0092-4fd2-a84c-daeff317dd48"
      },
      "outputs": [],
      "source": [
        "#defining parameters\n",
        "n_qubits = 8\n",
        "depth = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2a7c1c73-0907-4ee9-b995-ab8d33fea9ef",
      "metadata": {
        "id": "2a7c1c73-0907-4ee9-b995-ab8d33fea9ef"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import NesterovMomentumOptimizer\n",
        "from scipy import optimize\n",
        "from nftopt import nakanishi_fujii_todo as nftmethod"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00272b92-afad-423e-b45f-35353c92c4a9",
      "metadata": {
        "id": "00272b92-afad-423e-b45f-35353c92c4a9"
      },
      "source": [
        "We use the Logical Cat qubit version as the physical cat qubit version does not support the gate configurations that have been used in the circuit. Repo Link - <a> https://github.com/QuantumETS/pennylane-alice-bob/tree/main </a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8dd1f0e1-7dc0-40b1-b780-303853264e98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dd1f0e1-7dc0-40b1-b780-303853264e98",
        "outputId": "b13d7072-08bf-4f00-e9b5-c01e5b2762e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using alice & bob EMU:15Q:LOGICAL_EARLY backend...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RemoteDevice device (wires=8, shots=1024) at 0x7e9d6ff91e40>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# dev = qml.device(\"alicebob.qubit\", alice_backend=\"EMU:40Q:PHYSICAL_CATS\", wires=n_qubits, average_nb_photons=4,kappa_1=1e2, kappa_2=1e4, shots=1000)\n",
        "dev = qml.device(\"alicebob.qubit\", alice_backend=\"EMU:15Q:LOGICAL_EARLY\", wires=n_qubits)\n",
        "dev"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d56b886-e22f-4336-b0d5-360ef823a74f",
      "metadata": {
        "id": "1d56b886-e22f-4336-b0d5-360ef823a74f"
      },
      "source": [
        "A single Ansatz layer used for training contains set of trainiable RY gates for all the qubits followed by cyclic CZ arrangement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c2ffba23-faec-4557-b143-52c21b2d75f0",
      "metadata": {
        "id": "c2ffba23-faec-4557-b143-52c21b2d75f0"
      },
      "outputs": [],
      "source": [
        "def ansatz_layer(layer_weights, depth, n_qubits):\n",
        "    for dep in range(depth):\n",
        "        for wire in range(n_qubits):\n",
        "            qml.RY(layer_weights[wire+(n_qubits*dep)], wires=wire)\n",
        "\n",
        "        for i in range(n_qubits-1):\n",
        "            qml.CZ(wires=[i,i+1])\n",
        "        qml.CZ(wires=[n_qubits-1,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c245bd5-3e9d-4f38-bd38-d45dbe8788fa",
      "metadata": {
        "id": "9c245bd5-3e9d-4f38-bd38-d45dbe8788fa"
      },
      "source": [
        "We use the Fidelity as the accuracy metric in this case. The Fidelity estimate provides the similarity between the generated state and the required amplitude embedding. It returs 1 if there are similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7e480cd0-73f5-4222-843e-0905eee5b8c5",
      "metadata": {
        "id": "7e480cd0-73f5-4222-843e-0905eee5b8c5"
      },
      "outputs": [],
      "source": [
        "def accuracy(labels, predictions):\n",
        "  state0 = qml.math.dm_from_state_vector(labels)\n",
        "  state1 = qml.math.dm_from_state_vector(predictions)\n",
        "  return qml.math.fidelity(state0, state1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f6d051b0-8776-4c2d-a185-6942ece52e2f",
      "metadata": {
        "id": "f6d051b0-8776-4c2d-a185-6942ece52e2f"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev)\n",
        "def circuit(weights):\n",
        "  # since depth 4 was used\n",
        "  ansatz_layer(weights,depth=depth, n_qubits=n_qubits)\n",
        "  # qml.state() applies Ua to Ini State, which gives Appro_a\n",
        "  # return qml.state()\n",
        "  return qml.probs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e050d3ed-6542-4c7c-bd5a-0742604cccc0",
      "metadata": {
        "id": "e050d3ed-6542-4c7c-bd5a-0742604cccc0"
      },
      "outputs": [],
      "source": [
        "def variational_classifier(weights, x):\n",
        "    # weights are thetas\n",
        "    return np.real(circuit(weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data which have been used to get the weights by previous training"
      ],
      "metadata": {
        "id": "Nwit5Eodvvg2"
      },
      "id": "Nwit5Eodvvg2"
    },
    {
      "cell_type": "code",
      "source": [
        "value = np.loadtxt('8_qubit_data.out')\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHuNQ61WtnNA",
        "outputId": "7a65c43f-75c5-40e7-fcf5-576aa8b8cdd3"
      },
      "id": "RHuNQ61WtnNA",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08284764 0.04822248 0.04772381 0.07697001 0.06667772 0.04918233\n",
            " 0.07119205 0.06546178 0.0121052  0.03073409 0.0145168  0.0375386\n",
            " 0.04186722 0.06653349 0.03505152 0.08634318 0.04634064 0.04056781\n",
            " 0.06473209 0.06063315 0.06287014 0.07711482 0.03347822 0.02737753\n",
            " 0.07375131 0.07332574 0.04090799 0.08015003 0.0373481  0.08558989\n",
            " 0.0764542  0.0756789  0.08579295 0.07071218 0.06895074 0.07429418\n",
            " 0.0817577  0.02078277 0.07063666 0.05202572 0.08695379 0.05972889\n",
            " 0.04891439 0.07171632 0.07564259 0.0682474  0.06571066 0.06201586\n",
            " 0.05695638 0.04054239 0.03041083 0.05193202 0.08022291 0.08732516\n",
            " 0.05198229 0.0764754  0.07931452 0.08612146 0.05612533 0.08417969\n",
            " 0.00314346 0.0846016  0.08704915 0.08413478 0.05536368 0.06300987\n",
            " 0.03918602 0.07725638 0.02911662 0.05754946 0.02951604 0.04139544\n",
            " 0.08602274 0.07291232 0.05108132 0.03970532 0.00536753 0.04533982\n",
            " 0.0063251  0.08574067 0.06630697 0.08110905 0.07533784 0.05589753\n",
            " 0.04224634 0.06460819 0.05390607 0.05812747 0.0684402  0.07721571\n",
            " 0.04020943 0.05584219 0.057985   0.05361544 0.0100048  0.05809842\n",
            " 0.08176876 0.07602819 0.08554921 0.07130276 0.08528898 0.07717363\n",
            " 0.02903047 0.06954853 0.06335427 0.06809851 0.04644807 0.06997161\n",
            " 0.05539326 0.04806213 0.00805536 0.075363   0.01283845 0.04461665\n",
            " 0.07315913 0.03829986 0.08085656 0.06911957 0.07509605 0.07776947\n",
            " 0.05425448 0.07986995 0.06835566 0.02904265 0.05799273 0.00557126\n",
            " 0.03116962 0.07294919 0.0649327  0.03191244 0.07212284 0.01237669\n",
            " 0.08597381 0.07732247 0.06545228 0.06466014 0.03403745 0.01406026\n",
            " 0.03898828 0.06592617 0.07893816 0.06451884 0.03240628 0.06912518\n",
            " 0.08582063 0.04530039 0.02860766 0.06252618 0.08704057 0.06882655\n",
            " 0.08726059 0.02209005 0.06259159 0.07843623 0.07820587 0.08639989\n",
            " 0.03278283 0.0197859  0.05061222 0.03805541 0.03520649 0.05584531\n",
            " 0.08510208 0.07754538 0.06791609 0.06352011 0.06845496 0.04849213\n",
            " 0.08010584 0.06849907 0.03547921 0.05469638 0.03402941 0.0798288\n",
            " 0.06781927 0.07897092 0.0617392  0.07424885 0.06230131 0.05503553\n",
            " 0.05225741 0.0612647  0.06361143 0.03720661 0.02547131 0.06215197\n",
            " 0.05139154 0.07229717 0.06817307 0.05973992 0.08507972 0.06400058\n",
            " 0.06222517 0.07311969 0.08145536 0.04156095 0.0193265  0.06795462\n",
            " 0.07644392 0.08563479 0.05506453 0.06805107 0.06631359 0.06271368\n",
            " 0.06852876 0.08188373 0.05157266 0.05212047 0.0527967  0.05232288\n",
            " 0.06502264 0.07517091 0.04256686 0.05945834 0.05148368 0.01582166\n",
            " 0.01428518 0.07101963 0.07552054 0.07864566 0.05638342 0.07143649\n",
            " 0.06504718 0.06855515 0.07839738 0.08300858 0.08588477 0.032463\n",
            " 0.03757053 0.05022178 0.07178774 0.06071753 0.04296972 0.05843478\n",
            " 0.08098489 0.06885775 0.04703279 0.05221046 0.03988858 0.07788649\n",
            " 0.01668259 0.0848196  0.05304033 0.08683836 0.07594913 0.06333623\n",
            " 0.04492971 0.0822184  0.03157659 0.06316568 0.02552262 0.07942673\n",
            " 0.08485898 0.04018492 0.06382405 0.07034815]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the weights to prepare the amplitude embedding of the above data"
      ],
      "metadata": {
        "id": "nGJ8rIa4v4P5"
      },
      "id": "nGJ8rIa4v4P5"
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.loadtxt('8_qubit_weights.out')\n",
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLHV2SSctn7m",
        "outputId": "016af2d2-d58c-4ea2-9bf6-169fe3a9d985"
      },
      "id": "XLHV2SSctn7m",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7.07129103e+00  1.25722207e+01  4.56983192e+00  2.36785476e+00\n",
            "  1.57084698e+00  9.08351669e+00  1.13776435e+01  9.40771272e+00\n",
            "  1.17221282e+01 -2.19482400e-03  4.74860056e+00  3.21313709e+00\n",
            "  7.85353059e+00  9.42605276e+00  1.09674479e+01  9.42500297e+00\n",
            "  9.48882159e+00  1.10216109e+01  4.59130100e+00  4.78753353e+00\n",
            "  4.74872469e+00  1.10023146e+01  1.20897675e+00  1.09405914e+01\n",
            "  6.31600285e+00  6.29365534e+00  3.14158555e+00  7.65431967e-01\n",
            " -5.62693376e-02  1.29409569e+01  9.44179920e+00 -5.29899179e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213f0f4e-c26f-4bfb-91b0-3fb3ec188428",
      "metadata": {
        "id": "213f0f4e-c26f-4bfb-91b0-3fb3ec188428"
      },
      "source": [
        "We compite the fidelity of the generated states using VQSP and the original amplitude embedding needed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cat qubit library does not support gathering state vector from circuit, so we get the probabilities of the result.\n",
        "\n",
        "Since (Amplitude of state) ^ 2 = Probability,\n",
        "we compute the squre root of Probability before finding the fidelity of the states."
      ],
      "metadata": {
        "id": "p7jO2ooDv-L4"
      },
      "id": "p7jO2ooDv-L4"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d47ecf5f-7828-44a8-9417-be207174e056",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47ecf5f-7828-44a8-9417-be207174e056",
        "outputId": "e69a3edc-49ae-45d4-bfd5-8747acab073f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00390625 0.0078125  0.00097656 0.00097656 0.00390625 0.00292969\n",
            " 0.00097656 0.00292969 0.00195312 0.00683594 0.00097656 0.00390625\n",
            " 0.00488281 0.00097656 0.0078125  0.00097656 0.00292969 0.\n",
            " 0.00585938 0.00390625 0.00683594 0.00097656 0.00390625 0.00683594\n",
            " 0.00488281 0.00585938 0.00390625 0.00195312 0.00195312 0.00683594\n",
            " 0.00097656 0.00292969 0.00585938 0.00292969 0.00097656 0.00195312\n",
            " 0.00195312 0.0078125  0.00097656 0.00390625 0.00097656 0.00292969\n",
            " 0.00292969 0.         0.00585938 0.00488281 0.00195312 0.00390625\n",
            " 0.00585938 0.00683594 0.00292969 0.00585938 0.00488281 0.00683594\n",
            " 0.00195312 0.00195312 0.00097656 0.00488281 0.00292969 0.00585938\n",
            " 0.00585938 0.00683594 0.00292969 0.00878906 0.00390625 0.00488281\n",
            " 0.00195312 0.00488281 0.00195312 0.         0.00097656 0.00390625\n",
            " 0.00683594 0.00585938 0.00683594 0.00585938 0.00292969 0.\n",
            " 0.00292969 0.00488281 0.00195312 0.00683594 0.00488281 0.00390625\n",
            " 0.00292969 0.00195312 0.00683594 0.00195312 0.00585938 0.00292969\n",
            " 0.00292969 0.00097656 0.00390625 0.00292969 0.00488281 0.00195312\n",
            " 0.00292969 0.00390625 0.00488281 0.00292969 0.00195312 0.00097656\n",
            " 0.00390625 0.00585938 0.00292969 0.00390625 0.00292969 0.00097656\n",
            " 0.00488281 0.00292969 0.00292969 0.00292969 0.00390625 0.00390625\n",
            " 0.00585938 0.00488281 0.01074219 0.00585938 0.00585938 0.0078125\n",
            " 0.00390625 0.00097656 0.00195312 0.00195312 0.00292969 0.00683594\n",
            " 0.00585938 0.00292969 0.00488281 0.00097656 0.00292969 0.00488281\n",
            " 0.00390625 0.00292969 0.00488281 0.00292969 0.00292969 0.00390625\n",
            " 0.00390625 0.00683594 0.00683594 0.00585938 0.00683594 0.00195312\n",
            " 0.00488281 0.00195312 0.00390625 0.0078125  0.00390625 0.00585938\n",
            " 0.00390625 0.00195312 0.00195312 0.00292969 0.00585938 0.00195312\n",
            " 0.00195312 0.00097656 0.00683594 0.0078125  0.00390625 0.00390625\n",
            " 0.00390625 0.00195312 0.00390625 0.00683594 0.00390625 0.00195312\n",
            " 0.00390625 0.00488281 0.00292969 0.00292969 0.00488281 0.00292969\n",
            " 0.00488281 0.00390625 0.00292969 0.00195312 0.         0.00585938\n",
            " 0.00195312 0.00195312 0.00292969 0.00195312 0.00488281 0.00390625\n",
            " 0.00585938 0.00195312 0.00683594 0.00292969 0.00585938 0.00488281\n",
            " 0.00390625 0.00390625 0.00683594 0.00390625 0.00585938 0.00585938\n",
            " 0.00292969 0.00585938 0.00390625 0.00683594 0.00195312 0.01074219\n",
            " 0.00195312 0.00585938 0.00292969 0.00195312 0.00195312 0.00390625\n",
            " 0.00683594 0.00585938 0.00390625 0.00488281 0.00390625 0.00292969\n",
            " 0.00488281 0.00097656 0.00390625 0.00390625 0.00488281 0.00488281\n",
            " 0.00488281 0.00585938 0.00683594 0.00488281 0.00585938 0.00195312\n",
            " 0.00292969 0.00292969 0.00195312 0.00585938 0.         0.00390625\n",
            " 0.00585938 0.00292969 0.00292969 0.00097656 0.00683594 0.00390625\n",
            " 0.00585938 0.00097656 0.00195312 0.00292969 0.00292969 0.00683594\n",
            " 0.0078125  0.00195312 0.00585938 0.00683594 0.00292969 0.00488281\n",
            " 0.         0.00195312 0.00585938 0.00292969]\n",
            "0.8152557947705209\n"
          ]
        }
      ],
      "source": [
        "predictions=variational_classifier(weights,value)\n",
        "print(predictions)\n",
        "# Amp (qml.state) ^ 2 = prob (qml.prob)\n",
        "acc = accuracy(value, np.sqrt(predictions))\n",
        "# print(predictions.numpy(), x.numpy())\n",
        "print(acc)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}