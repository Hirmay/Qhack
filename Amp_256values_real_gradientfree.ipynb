{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e_S3eSpKP8xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8213d2c2-c4ae-463e-cc39-acbef601b5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.34.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nftopt\n",
            "  Downloading nftopt-0.0.1-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.2.1)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray>=0.6.1 (from pennylane)\n",
            "  Downloading autoray-0.6.8-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.2)\n",
            "Collecting pennylane-lightning>=0.34 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.34.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.9.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.2.2)\n",
            "Installing collected packages: semantic-version, rustworkx, autoray, nftopt, pennylane-lightning, pennylane\n",
            "Successfully installed autoray-0.6.8 nftopt-0.0.1 pennylane-0.34.0 pennylane-lightning-0.34.0 rustworkx-0.14.0 semantic-version-2.10.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install pennylane nftopt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# arr = []\n",
        "# for i in range(256):\n",
        "#   arr.append(1/256)\n",
        "\n",
        "# arr = np.array(arr)\n",
        "# print(arr)"
      ],
      "metadata": {
        "id": "LKd616nH8O2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr = np.random.rand(1,256)\n",
        "print(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGTk4AV29R4y",
        "outputId": "4e871a14-965f-42d3-c374-99a024db6987"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.64494975 0.9983475  0.84657812 0.48452119 0.39084177 0.30541591\n",
            "  0.91006393 0.45316097 0.70092859 0.19016603 0.29561208 0.38844691\n",
            "  0.45628678 0.24711698 0.18978742 0.90983018 0.98569438 0.00871219\n",
            "  0.52173491 0.35993281 0.22049975 0.07259503 0.17977841 0.46817033\n",
            "  0.26352262 0.61251969 0.4759611  0.46442821 0.97946321 0.90326843\n",
            "  0.77335068 0.22932426 0.2203521  0.97781107 0.0693043  0.09389387\n",
            "  0.82638321 0.68755247 0.90726111 0.80151695 0.41616821 0.20575367\n",
            "  0.83415092 0.68011979 0.78804395 0.29994948 0.0768441  0.09002431\n",
            "  0.84140926 0.85801449 0.45594483 0.02738024 0.96942872 0.59754626\n",
            "  0.46749911 0.27152295 0.42427163 0.01024485 0.46554149 0.58661386\n",
            "  0.31539874 0.43413329 0.84914824 0.10174096 0.59805639 0.58869913\n",
            "  0.85822889 0.27059124 0.35960685 0.73457653 0.79778826 0.3593671\n",
            "  0.92332486 0.64134032 0.33053361 0.4124786  0.67787779 0.28153181\n",
            "  0.19187443 0.88432798 0.44442116 0.21307866 0.97256903 0.72924828\n",
            "  0.3672578  0.17404328 0.34699167 0.03572695 0.91896736 0.08471165\n",
            "  0.90613873 0.38032405 0.10560727 0.42825309 0.05895871 0.50027338\n",
            "  0.49280542 0.81046465 0.37780862 0.86513081 0.08664235 0.03105649\n",
            "  0.36251951 0.73416122 0.79324823 0.85968733 0.02647171 0.92890041\n",
            "  0.42600034 0.72853796 0.19780357 0.7079459  0.66257057 0.43591357\n",
            "  0.14104962 0.48113373 0.66612263 0.82619343 0.72347624 0.45557363\n",
            "  0.47718217 0.31428161 0.93464812 0.58103526 0.07604585 0.73054006\n",
            "  0.61043926 0.36007251 0.93230431 0.1912568  0.52510615 0.17898893\n",
            "  0.93222832 0.91882694 0.45589444 0.78473114 0.67828471 0.00803941\n",
            "  0.82176808 0.99746379 0.88237585 0.8824255  0.95278835 0.54218301\n",
            "  0.45554551 0.19975381 0.48264805 0.22961477 0.46741291 0.43498481\n",
            "  0.12891482 0.06959248 0.36017152 0.61243354 0.87057822 0.28500672\n",
            "  0.20950103 0.47178535 0.7200185  0.3163629  0.71128772 0.23189619\n",
            "  0.31688878 0.63459828 0.14793617 0.99198409 0.31566737 0.3446461\n",
            "  0.52717232 0.40434352 0.11378048 0.34220442 0.69075951 0.78771591\n",
            "  0.50750417 0.20956797 0.80856672 0.90031592 0.2442144  0.95031126\n",
            "  0.38136107 0.80038588 0.02962532 0.59920007 0.63119106 0.77303394\n",
            "  0.84350746 0.22313528 0.93491018 0.2336594  0.54801037 0.47987337\n",
            "  0.12907186 0.04593986 0.91552666 0.78370366 0.77584154 0.42479025\n",
            "  0.91823413 0.09963693 0.16198556 0.78568783 0.7449412  0.70772087\n",
            "  0.44019088 0.68728103 0.56393181 0.16875892 0.09104669 0.74565233\n",
            "  0.99934077 0.91458278 0.86471369 0.68853198 0.88825159 0.98778147\n",
            "  0.70278313 0.00232384 0.47078867 0.05362724 0.12626035 0.45238158\n",
            "  0.1018097  0.04497929 0.50626136 0.33411889 0.02379055 0.45092456\n",
            "  0.41828118 0.25712233 0.84076729 0.16956262 0.19489907 0.11456203\n",
            "  0.76564743 0.54639399 0.85895158 0.21053532 0.35781486 0.43346321\n",
            "  0.70080261 0.07137259 0.04085083 0.4630014  0.08524075 0.79269866\n",
            "  0.8719206  0.38026196 0.99443842 0.44037604 0.36203349 0.11407788\n",
            "  0.37399264 0.7343689  0.77991146 0.36285397]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(arr)"
      ],
      "metadata": {
        "id": "GuY1qV2evgru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summer = np.sum(arr)\n",
        "print(summer)\n",
        "normalized_X = arr/summer\n",
        "print(normalized_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMpMS6myyaZ9",
        "outputId": "1d8fd018-1cb9-47e6-e820-b55062c99e13"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128.26185815919507\n",
            "[[5.02838303e-03 7.78366627e-03 6.60038871e-03 3.77759376e-03\n",
            "  3.04721746e-03 2.38119041e-03 7.09535903e-03 3.53309219e-03\n",
            "  5.46482481e-03 1.48263896e-03 2.30475437e-03 3.02854578e-03\n",
            "  3.55746272e-03 1.92665992e-03 1.47968711e-03 7.09353655e-03\n",
            "  7.68501561e-03 6.79250505e-05 4.06773236e-03 2.80623418e-03\n",
            "  1.71913737e-03 5.65990770e-04 1.40165134e-03 3.65011339e-03\n",
            "  2.05456730e-03 4.77554044e-03 3.71085457e-03 3.62093779e-03\n",
            "  7.63643400e-03 7.04237758e-03 6.02946729e-03 1.78793804e-03\n",
            "  1.71798616e-03 7.62355298e-03 5.40334483e-04 7.32048223e-04\n",
            "  6.44293812e-03 5.36053725e-03 7.07350664e-03 6.24906701e-03\n",
            "  3.24467627e-03 1.60416881e-03 6.50349938e-03 5.30258801e-03\n",
            "  6.14402413e-03 2.33857113e-03 5.99118870e-04 7.01879045e-04\n",
            "  6.56008942e-03 6.68955295e-03 3.55479667e-03 2.13471424e-04\n",
            "  7.55819954e-03 4.65879931e-03 3.64488023e-03 2.11694227e-03\n",
            "  3.30785502e-03 7.98744686e-05 3.62961756e-03 4.57356437e-03\n",
            "  2.45902208e-03 3.38474194e-03 6.62042679e-03 7.93228460e-04\n",
            "  4.66277663e-03 4.58982222e-03 6.69122451e-03 2.10967811e-03\n",
            "  2.80369285e-03 5.72716268e-03 6.21999612e-03 2.80182355e-03\n",
            "  7.19874853e-03 5.00024195e-03 2.57702188e-03 3.21591006e-03\n",
            "  5.28510812e-03 2.19497688e-03 1.49595857e-03 6.89470735e-03\n",
            "  3.46495181e-03 1.66127845e-03 7.58268318e-03 5.68562074e-03\n",
            "  2.86334381e-03 1.35693713e-03 2.70533794e-03 2.78546991e-04\n",
            "  7.16477508e-03 6.60458621e-04 7.06475600e-03 2.96521552e-03\n",
            "  8.23372366e-04 3.33889670e-03 4.59674529e-04 3.90040647e-03\n",
            "  3.84218213e-03 6.31882824e-03 2.94560385e-03 6.74503569e-03\n",
            "  6.75511431e-04 2.42133491e-04 2.82640153e-03 5.72392470e-03\n",
            "  6.18459956e-03 6.70259534e-03 2.06388048e-04 7.24221857e-03\n",
            "  3.32133301e-03 5.68008265e-03 1.54218543e-03 5.51953565e-03\n",
            "  5.16576460e-03 3.39862198e-03 1.09970046e-03 3.75118325e-03\n",
            "  5.19345842e-03 6.44145844e-03 5.64061875e-03 3.55190259e-03\n",
            "  3.72037467e-03 2.45031231e-03 7.28703089e-03 4.53007052e-03\n",
            "  5.92895246e-04 5.69569218e-03 4.75932025e-03 2.80732333e-03\n",
            "  7.26875726e-03 1.49114324e-03 4.09401642e-03 1.39549615e-03\n",
            "  7.26816477e-03 7.16368024e-03 3.55440381e-03 6.11819566e-03\n",
            "  5.28828068e-03 6.26796536e-05 6.40695602e-03 7.77677640e-03\n",
            "  6.87948748e-03 6.87987460e-03 7.42846206e-03 4.22715699e-03\n",
            "  3.55168340e-03 1.55739059e-03 3.76298970e-03 1.79020305e-03\n",
            "  3.64420814e-03 3.39138089e-03 1.00509087e-03 5.42581276e-04\n",
            "  2.80809532e-03 4.77486879e-03 6.78750670e-03 2.22206916e-03\n",
            "  1.63338526e-03 3.67829812e-03 5.61366029e-03 2.46653920e-03\n",
            "  5.54559034e-03 1.80799024e-03 2.47063927e-03 4.94767729e-03\n",
            "  1.15339175e-03 7.73405360e-03 2.46111648e-03 2.68705060e-03\n",
            "  4.11012540e-03 3.15248454e-03 8.87095206e-04 2.66801391e-03\n",
            "  5.38554109e-03 6.14146650e-03 3.95678169e-03 1.63390721e-03\n",
            "  6.30403094e-03 7.01935813e-03 1.90402983e-03 7.40914929e-03\n",
            "  2.97330064e-03 6.24024861e-03 2.30975252e-04 4.67169336e-03\n",
            "  4.92111268e-03 6.02699786e-03 6.57644815e-03 1.73968539e-03\n",
            "  7.28907407e-03 1.82173718e-03 4.27259027e-03 3.74135675e-03\n",
            "  1.00631521e-03 3.58172432e-04 7.13794945e-03 6.11018479e-03\n",
            "  6.04888742e-03 3.31189843e-03 7.15905841e-03 7.76824331e-04\n",
            "  1.26292854e-03 6.12565449e-03 5.80797135e-03 5.51778122e-03\n",
            "  3.43197024e-03 5.35842097e-03 4.39672256e-03 1.31573736e-03\n",
            "  7.09850071e-04 5.81351570e-03 7.79141032e-03 7.13059044e-03\n",
            "  6.74178360e-03 5.36817407e-03 6.92529798e-03 7.70128772e-03\n",
            "  5.47928386e-03 1.81179332e-05 3.67052746e-03 4.18107467e-04\n",
            "  9.84395140e-04 3.52701563e-03 7.93764457e-04 3.50683312e-04\n",
            "  3.94709201e-03 2.60497465e-03 1.85484233e-04 3.51565591e-03\n",
            "  3.26115018e-03 2.00466710e-03 6.55508426e-03 1.32200349e-03\n",
            "  1.51954035e-03 8.93188641e-04 5.96940850e-03 4.25998809e-03\n",
            "  6.69685903e-03 1.64144917e-03 2.78972149e-03 3.37951763e-03\n",
            "  5.46384263e-03 5.56459975e-04 3.18495548e-04 3.60981362e-03\n",
            "  6.64583807e-04 6.18031483e-03 6.79797258e-03 2.96473144e-03\n",
            "  7.75318892e-03 3.43341385e-03 2.82261221e-03 8.89413887e-04\n",
            "  2.91585233e-03 5.72554393e-03 6.08061874e-03 2.82900918e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining parameters\n",
        "n_qubits = 8\n",
        "depth = 4"
      ],
      "metadata": {
        "id": "uxqDzYPHP9gG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import NesterovMomentumOptimizer\n",
        "from scipy import optimize\n",
        "from nftopt import nakanishi_fujii_todo as nftmethod"
      ],
      "metadata": {
        "id": "LHEOby-1QAja"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"default.qubit\",wires=n_qubits)\n",
        "dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMFJbv1ZQCB1",
        "outputId": "80ba811b-e385-4a56-f000-c310ca97279f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<default.qubit device (wires=8) at 0x7afe23508fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ansatz_layer(layer_weights, depth, n_qubits):\n",
        "    for dep in range(depth):\n",
        "      for wire in range(n_qubits):\n",
        "        qml.RY(layer_weights[wire+(n_qubits*dep)], wires=wire)\n",
        "\n",
        "      qml.CZ(wires=[0,1])\n",
        "      qml.CZ(wires=[1,2])\n",
        "      qml.CZ(wires=[2,3])\n",
        "      qml.CZ(wires=[3,4])\n",
        "      qml.CZ(wires=[4,5])\n",
        "      qml.CZ(wires=[5,6])\n",
        "      qml.CZ(wires=[6,7])\n",
        "      qml.CZ(wires=[7,0])"
      ],
      "metadata": {
        "id": "c-OxlJ3QQDKK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(labels, predictions):\n",
        "  state0 = qml.math.dm_from_state_vector(labels)\n",
        "  state1 = qml.math.dm_from_state_vector(predictions)\n",
        "  return qml.math.fidelity(state0, state1)"
      ],
      "metadata": {
        "id": "FTW1SGK9QEoN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev,diff_method=\"backprop\")\n",
        "def circuit(weights):\n",
        "  # since depth 4 was used\n",
        "  ansatz_layer(weights,depth=depth, n_qubits=n_qubits)\n",
        "  # qml.state() applies Ua to Ini State, which gives Appro_a\n",
        "  return qml.state()"
      ],
      "metadata": {
        "id": "XR4C_aLQQGIy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_classifier(weights, x):\n",
        "    # weights are thetas\n",
        "    return np.real(circuit(weights))"
      ],
      "metadata": {
        "id": "JZGfLnJeQHjz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = np.array([0.083379922415887,0.049577998492674,0.989090451339352,0.049577998492674,0.049577998492674,0.049577998492674,0.049577998492674,0.049577998492674])\n",
        "# x = np.array([0.31622776601683794,0.31622776601683794,0.31622776601683794,0.4472135954999579,0.31622776601683794,0.31622776601683794,0.31622776601683794,0.4472135954999579])\n",
        "temp = []\n",
        "for i in range(len(normalized_X[0])):\n",
        "  temp.append(np.sqrt(normalized_X[0][i]))\n",
        "x = np.array(temp)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aI212uqQIlQ",
        "outputId": "c12b5ca1-9331-4147-88d1-da887bf4cea4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07091109 0.08822509 0.08124278 0.06146213 0.05520161 0.04879744\n",
            " 0.08423395 0.05943982 0.07392445 0.03850505 0.04800786 0.05503222\n",
            " 0.05964447 0.04389373 0.0384667  0.08422314 0.08766422 0.00824167\n",
            " 0.06377878 0.0529739  0.04146248 0.02379056 0.03743863 0.06041617\n",
            " 0.04532734 0.06910529 0.06091678 0.06017423 0.08738669 0.08391887\n",
            " 0.07764964 0.04228402 0.0414486  0.08731296 0.0232451  0.02705639\n",
            " 0.08026791 0.07321569 0.08410414 0.07905104 0.05696206 0.04005208\n",
            " 0.08064428 0.07281887 0.07838383 0.04835878 0.0244769  0.026493\n",
            " 0.08099438 0.08178969 0.05962212 0.01461066 0.08693791 0.0682554\n",
            " 0.06037284 0.04601024 0.05751396 0.00893725 0.06024631 0.06762813\n",
            " 0.04958853 0.05817854 0.08136601 0.02816431 0.06828453 0.06774823\n",
            " 0.08179991 0.04593123 0.05294991 0.07567802 0.07886695 0.05293225\n",
            " 0.08484544 0.07071239 0.05076438 0.05670899 0.07269875 0.04685058\n",
            " 0.03867762 0.08303437 0.05886384 0.04075878 0.0870786  0.07540306\n",
            " 0.05351022 0.03683663 0.05201286 0.01668973 0.08464499 0.02569939\n",
            " 0.0840521  0.05445379 0.02869447 0.05778319 0.02144002 0.06245323\n",
            " 0.06198534 0.07949106 0.05427342 0.08212817 0.0259906  0.01556064\n",
            " 0.05316391 0.07565662 0.07864223 0.08186938 0.01436621 0.08510123\n",
            " 0.05763101 0.07536632 0.03927067 0.07429358 0.07187325 0.0582977\n",
            " 0.03316173 0.0612469  0.07206565 0.0802587  0.07510405 0.05959784\n",
            " 0.06099487 0.04950063 0.08536411 0.0673058  0.02434944 0.07546981\n",
            " 0.06898783 0.05298418 0.08525701 0.03861532 0.0639845  0.03735634\n",
            " 0.08525353 0.08463853 0.05961882 0.0782189  0.07272057 0.00791705\n",
            " 0.08004346 0.08818603 0.08294268 0.08294501 0.08618853 0.06501659\n",
            " 0.059596   0.03946379 0.06134321 0.04231079 0.06036728 0.05823556\n",
            " 0.03170317 0.02329337 0.05299146 0.06910043 0.08238633 0.04713883\n",
            " 0.04041516 0.06064897 0.07492436 0.04966426 0.07446872 0.04252047\n",
            " 0.04970553 0.07033973 0.03396162 0.08794347 0.04960964 0.05183677\n",
            " 0.06411026 0.05614699 0.02978414 0.05165282 0.07338625 0.07836751\n",
            " 0.06290295 0.04042162 0.07939793 0.08378161 0.04363519 0.08607642\n",
            " 0.05452798 0.07899524 0.01519787 0.06834979 0.07015064 0.07763374\n",
            " 0.0810953  0.04170954 0.08537607 0.04268181 0.06536505 0.06116663\n",
            " 0.03172247 0.01892544 0.08448639 0.07816767 0.07777459 0.0575491\n",
            " 0.08461122 0.02787157 0.03553771 0.07826656 0.07621005 0.07428177\n",
            " 0.05858302 0.07320124 0.06630779 0.03627309 0.02664301 0.07624641\n",
            " 0.08826897 0.08444282 0.08210836 0.07326782 0.08321838 0.08775698\n",
            " 0.07402218 0.00425652 0.06058488 0.02044768 0.03137507 0.05938868\n",
            " 0.02817383 0.01872654 0.06282589 0.05103895 0.01361926 0.05929297\n",
            " 0.05710648 0.04477351 0.08096347 0.03635937 0.03898128 0.02988626\n",
            " 0.07726195 0.06526858 0.08183434 0.0405148  0.05281781 0.05813362\n",
            " 0.07391781 0.0235894  0.01784644 0.06008172 0.02577952 0.07861498\n",
            " 0.08244982 0.05444935 0.08805219 0.05859534 0.05312826 0.02982304\n",
            " 0.05399863 0.07566732 0.07797832 0.05318843]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i in range(len(x)):\n",
        "  sum += x[i]**2\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9IqJ70dphm0",
        "outputId": "834c4b9f-8f3d-42f6-929a-74800583ef80"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def F1_loss(a,Appro_a):\n",
        "  #   Define the cost function\n",
        "  F1=(a[0]**2)*np.log2((Appro_a[0]**2)/(a[0]**2))+(a[1]**2)*np.log2((Appro_a[1]**2)/(a[1]**2))+(a[2]**2)*np.log2((Appro_a[2]**2)/(a[2]**2))\n",
        "  F2=(a[3]**2)*np.log2((Appro_a[3]**2)/(a[3]**2))+(a[4]**2)*np.log2((Appro_a[4]**2)/(a[4]**2))+(a[5]**2)*np.log2((Appro_a[5]**2)/(a[5]**2))\n",
        "  F3=(a[6]**2)*np.log2((Appro_a[6]**2)/(a[6]**2))+(a[7]**2)*np.log2((Appro_a[7]**2)/(a[7]**2))\n",
        "\n",
        "  #   Prepare the Bell state\n",
        "  Bell_State=np.ones((8,1))/np.linalg.norm(np.ones((8,1)))\n",
        "  #   The sum of vector a\n",
        "  Sum_a=np.sum(a)\n",
        "  sqrt_D = np.linalg.norm(np.ones((8,1)))\n",
        "  UaFunction=np.abs(Sum_a -  (sqrt_D * np.matmul(np.transpose(Bell_State), Appro_a)))-(F1+F2+F3)\n",
        "  return np.real(UaFunction)"
      ],
      "metadata": {
        "id": "Xgysu4MgQKBz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def F1_loss(a,Appro_a):\n",
        "  #   Define the cost function\n",
        "  F1 = 0.\n",
        "  for i in range(256):\n",
        "    F1 += (a[i]**2)*np.log2((Appro_a[i]**2)/(a[i]**2))\n",
        "\n",
        "  # F1=(a[0]**2)*np.log2((Appro_a[0]**2)/(a[0]**2))+(a[1]**2)*np.log2((Appro_a[1]**2)/(a[1]**2))+(a[2]**2)*np.log2((Appro_a[2]**2)/(a[2]**2))\n",
        "  # F2=(a[3]**2)*np.log2((Appro_a[3]**2)/(a[3]**2))+(a[4]**2)*np.log2((Appro_a[4]**2)/(a[4]**2))+(a[5]**2)*np.log2((Appro_a[5]**2)/(a[5]**2))\n",
        "  # F3=(a[6]**2)*np.log2((Appro_a[6]**2)/(a[6]**2))+(a[7]**2)*np.log2((Appro_a[7]**2)/(a[7]**2))\n",
        "\n",
        "  #   Prepare the Bell state\n",
        "  states = 2**n_qubits\n",
        "  Bell_State=np.ones((states,1))/np.linalg.norm(np.ones((states,1)))\n",
        "  #   The sum of vector a\n",
        "  Sum_a=np.sum(a)\n",
        "  sqrt_D = np.linalg.norm(np.ones((states,1)))\n",
        "  UaFunction=np.abs(Sum_a -  (sqrt_D * np.matmul(np.transpose(Bell_State), Appro_a)))-(F1)\n",
        "  return np.real(UaFunction)"
      ],
      "metadata": {
        "id": "eDGI-EXh6Jhl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= x"
      ],
      "metadata": {
        "id": "ThuF1UTmogie"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(weights, X=x):\n",
        "    # X is our preparation state\n",
        "    Appro_a = variational_classifier(weights, X)\n",
        "    return F1_loss(X, Appro_a)"
      ],
      "metadata": {
        "id": "Z9jjzQJFQq-O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = 4*np.pi*np.random.rand(n_qubits * depth)\n",
        "result= optimize.minimize(cost,weights, method=nftmethod, options={'maxfev':2000})\n"
      ],
      "metadata": {
        "id": "dhuy_o6ZQvPY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpzlr_C7QsYZ",
        "outputId": "ec0497a8-c584-44b9-cdc5-9154b7279244"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.70630057,  3.46629087, 12.28670403, 11.37207788,  6.2602373 ,\n",
              "       10.89261346,  6.32556393,  2.88526113,  0.09146338,  4.72497145,\n",
              "       -0.12093828,  7.47217785,  6.07368169,  4.79856298,  3.15821738,\n",
              "        4.64687359,  7.86183387,  9.11753195, 11.03911367,  4.67607412,\n",
              "        4.5331367 , 10.97302782,  1.57648483,  2.90052914, 12.14408298,\n",
              "        6.2649404 , 12.26415949,  9.4293738 ,  6.27555625,  6.25728562,\n",
              "       12.48253204,  9.41063055])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=variational_classifier(result.x,a)\n",
        "acc = accuracy(x, predictions)\n",
        "print(predictions.numpy(), x.numpy())\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y3eA9FWRQnj",
        "outputId": "d5a10562-80cf-4bc3-d95e-bb4426186888"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0745552  0.06353757 0.06870998 0.0645037  0.0698083  0.06598289\n",
            " 0.07516542 0.06346264 0.068519   0.05936077 0.06787638 0.06222937\n",
            " 0.06656056 0.06149868 0.06661987 0.05725715 0.06715338 0.05803576\n",
            " 0.06216926 0.05873961 0.06149631 0.05858218 0.06600885 0.05655468\n",
            " 0.06650421 0.05815481 0.06565148 0.06121737 0.0660918  0.06207391\n",
            " 0.0664797  0.05758951 0.0656142  0.05523438 0.06073708 0.05584714\n",
            " 0.06181537 0.05729217 0.06628783 0.0553469  0.06673444 0.05692649\n",
            " 0.06581421 0.05996547 0.06456828 0.05923406 0.06494371 0.05489656\n",
            " 0.07157659 0.05962503 0.06600482 0.06063539 0.06529872 0.06043043\n",
            " 0.07044042 0.05810606 0.06374386 0.05391912 0.06327483 0.05650931\n",
            " 0.0637883  0.05745987 0.06389324 0.05360052 0.06148611 0.05825776\n",
            " 0.05705494 0.058548   0.0580764  0.06043462 0.06229265 0.05816715\n",
            " 0.06300487 0.06049064 0.06231672 0.06330621 0.06096221 0.06273858\n",
            " 0.06130109 0.05795774 0.06840414 0.0641418  0.06323981 0.06484159\n",
            " 0.06238407 0.06483418 0.06732039 0.0621081  0.06045616 0.05761919\n",
            " 0.06019618 0.05999325 0.06068537 0.06138421 0.06077557 0.05707956\n",
            " 0.07043044 0.0672715  0.06507022 0.06790203 0.06591773 0.06966347\n",
            " 0.07099508 0.06676659 0.06418171 0.06233276 0.06376183 0.06494056\n",
            " 0.0625184  0.06455359 0.06256597 0.05991636 0.06204026 0.0600397\n",
            " 0.05756538 0.06041984 0.05695039 0.06061427 0.06114456 0.05830726\n",
            " 0.06201275 0.06076114 0.06138971 0.06355911 0.06161289 0.06462809\n",
            " 0.06195388 0.05977657 0.06630081 0.06717848 0.06298718 0.06598281\n",
            " 0.06197697 0.06963691 0.06873441 0.06486709 0.06074725 0.06276144\n",
            " 0.06205331 0.06363691 0.05903114 0.06487783 0.06082367 0.05851394\n",
            " 0.05993672 0.06036367 0.05722755 0.05908977 0.05488407 0.06075924\n",
            " 0.06065251 0.05682078 0.05952589 0.06046852 0.06060335 0.06153963\n",
            " 0.05911166 0.06442929 0.06120789 0.0579183  0.05950728 0.06131827\n",
            " 0.05680303 0.05997603 0.05606193 0.06341758 0.06188025 0.0593434\n",
            " 0.06059309 0.06276959 0.06161858 0.06391912 0.05858585 0.06519041\n",
            " 0.06065113 0.05855451 0.06448743 0.06650505 0.0612897  0.06542706\n",
            " 0.05873341 0.06727715 0.06525134 0.06266225 0.05733088 0.06051871\n",
            " 0.05867737 0.06135618 0.05739814 0.06434137 0.05917151 0.0581374\n",
            " 0.06455222 0.0593391  0.06127442 0.05820256 0.06084564 0.06155289\n",
            " 0.06695108 0.05760265 0.0662354  0.06120014 0.06698319 0.06249783\n",
            " 0.0638832  0.06355802 0.06592702 0.05709047 0.07134279 0.06564461\n",
            " 0.06746482 0.06473602 0.06485819 0.06638298 0.07180083 0.06186697\n",
            " 0.06299399 0.05928077 0.06409242 0.0603061  0.06306788 0.06324278\n",
            " 0.0648488  0.0571223  0.07252889 0.065346   0.06853733 0.06435272\n",
            " 0.06765192 0.06771967 0.07477042 0.06310555 0.06592886 0.06052201\n",
            " 0.06694864 0.06156735 0.06406149 0.06275618 0.06581968 0.05658659\n",
            " 0.06412207 0.05737774 0.06088118 0.05631707 0.05875042 0.05791261\n",
            " 0.06470473 0.05417166 0.06430215 0.05802704 0.06508013 0.0592378\n",
            " 0.06366451 0.06182222 0.06571996 0.05556352] [0.07091109 0.08822509 0.08124278 0.06146213 0.05520161 0.04879744\n",
            " 0.08423395 0.05943982 0.07392445 0.03850505 0.04800786 0.05503222\n",
            " 0.05964447 0.04389373 0.0384667  0.08422314 0.08766422 0.00824167\n",
            " 0.06377878 0.0529739  0.04146248 0.02379056 0.03743863 0.06041617\n",
            " 0.04532734 0.06910529 0.06091678 0.06017423 0.08738669 0.08391887\n",
            " 0.07764964 0.04228402 0.0414486  0.08731296 0.0232451  0.02705639\n",
            " 0.08026791 0.07321569 0.08410414 0.07905104 0.05696206 0.04005208\n",
            " 0.08064428 0.07281887 0.07838383 0.04835878 0.0244769  0.026493\n",
            " 0.08099438 0.08178969 0.05962212 0.01461066 0.08693791 0.0682554\n",
            " 0.06037284 0.04601024 0.05751396 0.00893725 0.06024631 0.06762813\n",
            " 0.04958853 0.05817854 0.08136601 0.02816431 0.06828453 0.06774823\n",
            " 0.08179991 0.04593123 0.05294991 0.07567802 0.07886695 0.05293225\n",
            " 0.08484544 0.07071239 0.05076438 0.05670899 0.07269875 0.04685058\n",
            " 0.03867762 0.08303437 0.05886384 0.04075878 0.0870786  0.07540306\n",
            " 0.05351022 0.03683663 0.05201286 0.01668973 0.08464499 0.02569939\n",
            " 0.0840521  0.05445379 0.02869447 0.05778319 0.02144002 0.06245323\n",
            " 0.06198534 0.07949106 0.05427342 0.08212817 0.0259906  0.01556064\n",
            " 0.05316391 0.07565662 0.07864223 0.08186938 0.01436621 0.08510123\n",
            " 0.05763101 0.07536632 0.03927067 0.07429358 0.07187325 0.0582977\n",
            " 0.03316173 0.0612469  0.07206565 0.0802587  0.07510405 0.05959784\n",
            " 0.06099487 0.04950063 0.08536411 0.0673058  0.02434944 0.07546981\n",
            " 0.06898783 0.05298418 0.08525701 0.03861532 0.0639845  0.03735634\n",
            " 0.08525353 0.08463853 0.05961882 0.0782189  0.07272057 0.00791705\n",
            " 0.08004346 0.08818603 0.08294268 0.08294501 0.08618853 0.06501659\n",
            " 0.059596   0.03946379 0.06134321 0.04231079 0.06036728 0.05823556\n",
            " 0.03170317 0.02329337 0.05299146 0.06910043 0.08238633 0.04713883\n",
            " 0.04041516 0.06064897 0.07492436 0.04966426 0.07446872 0.04252047\n",
            " 0.04970553 0.07033973 0.03396162 0.08794347 0.04960964 0.05183677\n",
            " 0.06411026 0.05614699 0.02978414 0.05165282 0.07338625 0.07836751\n",
            " 0.06290295 0.04042162 0.07939793 0.08378161 0.04363519 0.08607642\n",
            " 0.05452798 0.07899524 0.01519787 0.06834979 0.07015064 0.07763374\n",
            " 0.0810953  0.04170954 0.08537607 0.04268181 0.06536505 0.06116663\n",
            " 0.03172247 0.01892544 0.08448639 0.07816767 0.07777459 0.0575491\n",
            " 0.08461122 0.02787157 0.03553771 0.07826656 0.07621005 0.07428177\n",
            " 0.05858302 0.07320124 0.06630779 0.03627309 0.02664301 0.07624641\n",
            " 0.08826897 0.08444282 0.08210836 0.07326782 0.08321838 0.08775698\n",
            " 0.07402218 0.00425652 0.06058488 0.02044768 0.03137507 0.05938868\n",
            " 0.02817383 0.01872654 0.06282589 0.05103895 0.01361926 0.05929297\n",
            " 0.05710648 0.04477351 0.08096347 0.03635937 0.03898128 0.02988626\n",
            " 0.07726195 0.06526858 0.08183434 0.0405148  0.05281781 0.05813362\n",
            " 0.07391781 0.0235894  0.01784644 0.06008172 0.02577952 0.07861498\n",
            " 0.08244982 0.05444935 0.08805219 0.05859534 0.05312826 0.02982304\n",
            " 0.05399863 0.07566732 0.07797832 0.05318843]\n",
            "0.8916111774720593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VB43gUKQRVnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}